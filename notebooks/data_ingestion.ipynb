{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import missingno as msno\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Move one level up\n",
    "parent_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "env_path = os.path.join(parent_directory, 'analysis.env')\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Get database connection details\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_PORT = os.getenv('DB_PORT')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "DB_OPTIONS = os.getenv('DB_OPTIONS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_only_user\n"
     ]
    }
   ],
   "source": [
    "print(DB_USER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create the SQLAlchemy engine\n",
    "db_engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\",\n",
    "    connect_args={'options': DB_OPTIONS}\n",
    ")\n",
    "print('Database engine created successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFetcher:\n",
    "    def __init__(self, db_engine, interval_days=7, chunk_size=10000):\n",
    "        \"\"\"\n",
    "        Initializes the DataFetcher with a database engine, interval (in days), and chunk size.\n",
    "        \n",
    "        Args:\n",
    "        - db_engine: SQLAlchemy database engine\n",
    "        - interval_days: Number of days to fetch data per query (default: 7 days)\n",
    "        - chunk_size: Number of rows per chunk (default: 10,000)\n",
    "        \"\"\"\n",
    "        self.db_engine = db_engine\n",
    "        self.interval_days = interval_days\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def get_oldest_date(self):\n",
    "        \"\"\"Fetches the earliest created_at timestamp from the database.\"\"\"\n",
    "        query = \"SELECT MIN(created_at) FROM applied_discount_codes\"\n",
    "        try:\n",
    "            result = pd.read_sql(query, self.db_engine)\n",
    "            oldest_date = result.iloc[0, 0]  # Extract the first value\n",
    "            if oldest_date is not None and oldest_date.tzinfo is None:\n",
    "                oldest_date = oldest_date.replace(tzinfo=timezone.utc)  # Ensure it's timezone-aware\n",
    "            return oldest_date\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching oldest date: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_data_in_intervals(self, start_date=None, end_date=None):\n",
    "        \"\"\"\n",
    "        Fetches data in smaller intervals from the given start_date to end_date.\n",
    "        \n",
    "        If no start_date is provided, it fetches from the **earliest available** date in the database.\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with all fetched data, or None if no data is retrieved.\n",
    "        \"\"\"\n",
    "        if start_date is None:\n",
    "            start_date = self.get_oldest_date()\n",
    "        if end_date is None:\n",
    "            end_date = datetime.now(timezone.utc)  # Ensure timezone-aware\n",
    "\n",
    "        if start_date is None:\n",
    "            print(\"No data found in the database.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Fetching data from {start_date} to {end_date}...\")\n",
    "\n",
    "        chunks = []\n",
    "        current_start = start_date\n",
    "\n",
    "        while current_start < end_date:\n",
    "            current_end = current_start + timedelta(days=self.interval_days)\n",
    "            offset = 0  # Start with zero offset for pagination\n",
    "\n",
    "            while True:\n",
    "                query = f\"\"\"\n",
    "                select a.*,token,subtotal_price,total_price,order_name,is_payment_online,\n",
    "                        verified_cart,final_subtotal_price,final_total_price,cart_state,final_discount,\n",
    "                        final_shipping,outstation,online_payment_attempted,utm_source,is_fast_checkout,\n",
    "                        recommended_discount_id,temp_discount,discount_reason,additional_off,additional_off_type,\n",
    "                        eligible_nat_cash,discount_amount,discount_type,payment_charge,promotion_discount_amount,\n",
    "                        d.discount_code as recommend_discount_code,min_amount,is_active,suggestion_amount_window,\n",
    "                        show_only_on_checkout,background_color,image_url,show_on_new_website,\n",
    "                        recommendation_tag,mrp_total,mrp_items_total,\n",
    "                        show_on_only_promotion_qty,show_on_app\n",
    "                        from applied_discount_codes a\n",
    "                        left join cart c on c.id = a.cart_id\n",
    "                        left join discount_recommendation d on d.id = c.recommended_discount_id\n",
    "                        WHERE a.created_at >= '{current_start.strftime('%Y-%m-%d')}'\n",
    "                        AND a.created_at < '{current_end.strftime('%Y-%m-%d')}'\n",
    "                        ORDER BY a.created_at\n",
    "                        LIMIT {self.chunk_size} OFFSET {offset}\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    chunk = pd.read_sql(query, self.db_engine)\n",
    "                    if chunk.empty:\n",
    "                        break  # No more data for this interval\n",
    "                    print(f\"Fetched {len(chunk)} rows from {current_start.strftime('%Y-%m-%d')} to {current_end.strftime('%Y-%m-%d')} (offset {offset})\")\n",
    "                    chunks.append(chunk)\n",
    "                    offset += self.chunk_size  # Move to next chunk\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    break  # Move to next interval\n",
    "\n",
    "            current_start = current_end  # Move to next weekly interval\n",
    "\n",
    "        if chunks:\n",
    "            df = pd.concat(chunks, ignore_index=True)\n",
    "            print(f\"✅ Successfully fetched {len(df)} rows from {start_date} to {end_date}!\")\n",
    "            return df\n",
    "        else:\n",
    "            print(\"No data fetched.\")\n",
    "            return None\n",
    "\n",
    "    def fetch_manual_date_range(self, df, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Fetches data for a user-specified date range and appends it to an existing DataFrame.\n",
    "        \n",
    "        Args:\n",
    "        - df: Existing DataFrame\n",
    "        - start_date: Start date for fetching data\n",
    "        - end_date: End date for fetching data\n",
    "        \n",
    "        Returns:\n",
    "        - Updated DataFrame with newly fetched data appended.\n",
    "        \"\"\"\n",
    "        manual_df = self.fetch_data_in_intervals(start_date, end_date)\n",
    "        if manual_df is not None:\n",
    "            df = pd.concat([df, manual_df], ignore_index=True)\n",
    "            print(\"✅ Manual data appended successfully!\")\n",
    "        return df\n",
    "\n",
    "    def close_connection(self):\n",
    "        \"\"\"Closes the database connection.\"\"\"\n",
    "        self.db_engine.dispose()\n",
    "        print(\"Database engine disposed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFetcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2023-03-14 05:10:02.591782+00:00 to 2025-03-28 13:03:38.597164+00:00...\n",
      "Fetched 17837 rows from 2023-03-14 to 2023-03-28 (offset 0)\n",
      "Fetched 26692 rows from 2023-03-28 to 2023-04-11 (offset 0)\n",
      "Fetched 28218 rows from 2023-04-11 to 2023-04-25 (offset 0)\n",
      "Fetched 26328 rows from 2023-04-25 to 2023-05-09 (offset 0)\n",
      "Fetched 27817 rows from 2023-05-09 to 2023-05-23 (offset 0)\n",
      "Fetched 28251 rows from 2023-05-23 to 2023-06-06 (offset 0)\n",
      "Fetched 40020 rows from 2023-06-06 to 2023-06-20 (offset 0)\n",
      "Fetched 39122 rows from 2023-06-20 to 2023-07-04 (offset 0)\n",
      "Fetched 28370 rows from 2023-07-04 to 2023-07-18 (offset 0)\n",
      "Fetched 34633 rows from 2023-07-18 to 2023-08-01 (offset 0)\n",
      "Fetched 41330 rows from 2023-08-01 to 2023-08-15 (offset 0)\n",
      "Fetched 36913 rows from 2023-08-15 to 2023-08-29 (offset 0)\n",
      "Fetched 37491 rows from 2023-08-29 to 2023-09-12 (offset 0)\n",
      "Fetched 37991 rows from 2023-09-12 to 2023-09-26 (offset 0)\n",
      "Fetched 50000 rows from 2023-09-26 to 2023-10-10 (offset 0)\n",
      "Fetched 4534 rows from 2023-09-26 to 2023-10-10 (offset 50000)\n",
      "Fetched 32050 rows from 2023-10-10 to 2023-10-24 (offset 0)\n",
      "Fetched 38703 rows from 2023-10-24 to 2023-11-07 (offset 0)\n",
      "Fetched 40551 rows from 2023-11-07 to 2023-11-21 (offset 0)\n",
      "Fetched 40529 rows from 2023-11-21 to 2023-12-05 (offset 0)\n",
      "Fetched 50000 rows from 2023-12-05 to 2023-12-19 (offset 0)\n",
      "Fetched 14531 rows from 2023-12-05 to 2023-12-19 (offset 50000)\n",
      "Fetched 42308 rows from 2023-12-19 to 2024-01-02 (offset 0)\n",
      "Fetched 41843 rows from 2024-01-02 to 2024-01-16 (offset 0)\n",
      "Fetched 50000 rows from 2024-01-16 to 2024-01-30 (offset 0)\n",
      "Fetched 3856 rows from 2024-01-16 to 2024-01-30 (offset 50000)\n",
      "Fetched 50000 rows from 2024-01-30 to 2024-02-13 (offset 0)\n",
      "Fetched 4193 rows from 2024-01-30 to 2024-02-13 (offset 50000)\n",
      "Fetched 50000 rows from 2024-02-13 to 2024-02-27 (offset 0)\n",
      "Fetched 13782 rows from 2024-02-13 to 2024-02-27 (offset 50000)\n",
      "Fetched 50000 rows from 2024-02-27 to 2024-03-12 (offset 0)\n",
      "Fetched 50000 rows from 2024-02-27 to 2024-03-12 (offset 50000)\n",
      "Fetched 16536 rows from 2024-02-27 to 2024-03-12 (offset 100000)\n",
      "Fetched 50000 rows from 2024-03-12 to 2024-03-26 (offset 0)\n",
      "Fetched 39347 rows from 2024-03-12 to 2024-03-26 (offset 50000)\n",
      "Fetched 50000 rows from 2024-03-26 to 2024-04-09 (offset 0)\n",
      "Fetched 34239 rows from 2024-03-26 to 2024-04-09 (offset 50000)\n",
      "Fetched 50000 rows from 2024-04-09 to 2024-04-23 (offset 0)\n",
      "Fetched 32233 rows from 2024-04-09 to 2024-04-23 (offset 50000)\n",
      "Fetched 50000 rows from 2024-04-23 to 2024-05-07 (offset 0)\n",
      "Fetched 50000 rows from 2024-04-23 to 2024-05-07 (offset 50000)\n",
      "Fetched 40373 rows from 2024-04-23 to 2024-05-07 (offset 100000)\n",
      "Fetched 50000 rows from 2024-05-07 to 2024-05-21 (offset 0)\n",
      "Fetched 34260 rows from 2024-05-07 to 2024-05-21 (offset 50000)\n",
      "Fetched 50000 rows from 2024-05-21 to 2024-06-04 (offset 0)\n",
      "Fetched 43115 rows from 2024-05-21 to 2024-06-04 (offset 50000)\n",
      "Fetched 50000 rows from 2024-06-04 to 2024-06-18 (offset 0)\n",
      "Fetched 44517 rows from 2024-06-04 to 2024-06-18 (offset 50000)\n",
      "Fetched 50000 rows from 2024-06-18 to 2024-07-02 (offset 0)\n",
      "Fetched 50000 rows from 2024-06-18 to 2024-07-02 (offset 50000)\n",
      "Fetched 11863 rows from 2024-06-18 to 2024-07-02 (offset 100000)\n",
      "Fetched 50000 rows from 2024-07-02 to 2024-07-16 (offset 0)\n",
      "Fetched 50000 rows from 2024-07-02 to 2024-07-16 (offset 50000)\n",
      "Fetched 17146 rows from 2024-07-02 to 2024-07-16 (offset 100000)\n",
      "Fetched 50000 rows from 2024-07-16 to 2024-07-30 (offset 0)\n",
      "Fetched 42923 rows from 2024-07-16 to 2024-07-30 (offset 50000)\n",
      "Fetched 50000 rows from 2024-07-30 to 2024-08-13 (offset 0)\n",
      "Fetched 50000 rows from 2024-07-30 to 2024-08-13 (offset 50000)\n",
      "Fetched 24681 rows from 2024-07-30 to 2024-08-13 (offset 100000)\n",
      "Fetched 50000 rows from 2024-08-13 to 2024-08-27 (offset 0)\n",
      "Fetched 50000 rows from 2024-08-13 to 2024-08-27 (offset 50000)\n",
      "Fetched 5755 rows from 2024-08-13 to 2024-08-27 (offset 100000)\n",
      "Fetched 50000 rows from 2024-08-27 to 2024-09-10 (offset 0)\n",
      "Fetched 32347 rows from 2024-08-27 to 2024-09-10 (offset 50000)\n",
      "Fetched 50000 rows from 2024-09-10 to 2024-09-24 (offset 0)\n",
      "Fetched 40539 rows from 2024-09-10 to 2024-09-24 (offset 50000)\n",
      "Fetched 50000 rows from 2024-09-24 to 2024-10-08 (offset 0)\n",
      "Fetched 44964 rows from 2024-09-24 to 2024-10-08 (offset 50000)\n",
      "Fetched 50000 rows from 2024-10-08 to 2024-10-22 (offset 0)\n",
      "Fetched 39322 rows from 2024-10-08 to 2024-10-22 (offset 50000)\n",
      "Fetched 50000 rows from 2024-10-22 to 2024-11-05 (offset 0)\n",
      "Fetched 29473 rows from 2024-10-22 to 2024-11-05 (offset 50000)\n",
      "Fetched 50000 rows from 2024-11-05 to 2024-11-19 (offset 0)\n",
      "Fetched 50000 rows from 2024-11-05 to 2024-11-19 (offset 50000)\n",
      "Fetched 19277 rows from 2024-11-05 to 2024-11-19 (offset 100000)\n",
      "Fetched 50000 rows from 2024-11-19 to 2024-12-03 (offset 0)\n",
      "Fetched 41544 rows from 2024-11-19 to 2024-12-03 (offset 50000)\n",
      "Fetched 50000 rows from 2024-12-03 to 2024-12-17 (offset 0)\n",
      "Fetched 39964 rows from 2024-12-03 to 2024-12-17 (offset 50000)\n",
      "Fetched 50000 rows from 2024-12-17 to 2024-12-31 (offset 0)\n",
      "Fetched 36765 rows from 2024-12-17 to 2024-12-31 (offset 50000)\n",
      "Fetched 50000 rows from 2024-12-31 to 2025-01-14 (offset 0)\n",
      "Fetched 50000 rows from 2024-12-31 to 2025-01-14 (offset 50000)\n",
      "Fetched 39518 rows from 2024-12-31 to 2025-01-14 (offset 100000)\n",
      "Fetched 50000 rows from 2025-01-14 to 2025-01-28 (offset 0)\n",
      "Fetched 49396 rows from 2025-01-14 to 2025-01-28 (offset 50000)\n",
      "Fetched 50000 rows from 2025-01-28 to 2025-02-11 (offset 0)\n",
      "Fetched 50000 rows from 2025-01-28 to 2025-02-11 (offset 50000)\n",
      "Fetched 27193 rows from 2025-01-28 to 2025-02-11 (offset 100000)\n",
      "Fetched 50000 rows from 2025-02-11 to 2025-02-25 (offset 0)\n",
      "Fetched 45567 rows from 2025-02-11 to 2025-02-25 (offset 50000)\n",
      "Fetched 50000 rows from 2025-02-25 to 2025-03-11 (offset 0)\n",
      "Fetched 50000 rows from 2025-02-25 to 2025-03-11 (offset 50000)\n",
      "Fetched 37620 rows from 2025-02-25 to 2025-03-11 (offset 100000)\n",
      "Fetched 50000 rows from 2025-03-11 to 2025-03-25 (offset 0)\n",
      "Fetched 50000 rows from 2025-03-11 to 2025-03-25 (offset 50000)\n",
      "Fetched 2749 rows from 2025-03-11 to 2025-03-25 (offset 100000)\n",
      "Fetched 25341 rows from 2025-03-25 to 2025-04-08 (offset 0)\n",
      "✅ Successfully fetched 3866460 rows from 2023-03-14 05:10:02.591782+00:00 to 2025-03-28 13:03:38.597164+00:00!\n"
     ]
    }
   ],
   "source": [
    "# Usage Example\n",
    "# db_engine should be an SQLAlchemy engine, e.g., `db_engine = create_engine(\"postgresql://user:pass@host/db\")`\n",
    "data_fetcher = DataFetcher(db_engine, interval_days=14, chunk_size=50000)\n",
    "\n",
    "# Fetch all historical data automatically\n",
    "df = data_fetcher.fetch_data_in_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['created_at']> '2024-03-31'].to_csv('data_from_2024_04.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_fetched.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
